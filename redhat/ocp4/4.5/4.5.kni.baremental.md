# 4.5 kni baremental

https://github.com/RHFieldProductManagement/baremetal-ipi-lab

```bash

oc version
export VERSION=4.5.12
./openshift-baremetal-install version

sudo dnf -y install podman httpd httpd-tools
sudo mkdir -p /nfs/registry/{auth,certs,data}

sudo openssl req -newkey rsa:4096 -nodes -sha256 \
    -keyout /nfs/registry/certs/domain.key -x509 -days 365 -out /nfs/registry/certs/domain.crt \
    -subj "/C=US/ST=NorthCarolina/L=Raleigh/O=Red Hat/OU=Marketing/CN=provision.$GUID.dynamic.opentlc.com"
# Generating a RSA private key
# ..................................................................................................
# ..................................................................................................
# ..................................................................++++
# ..................................................................................................
# ..................................................................................................
# .........................................................++++
# writing new private key to '/nfs/registry/certs/domain.key'
# -----

sudo cp /nfs/registry/certs/domain.crt $HOME/scripts/domain.crt
sudo chown lab-user $HOME/scripts/domain.crt
sudo cp /nfs/registry/certs/domain.crt /etc/pki/ca-trust/source/anchors/
sudo update-ca-trust extract

sudo htpasswd -bBc /nfs/registry/auth/htpasswd dummy dummy
# Adding password for user dummy

sudo podman create --name poc-registry --net host -p 5000:5000 \
    -v /nfs/registry/data:/var/lib/registry:z -v /nfs/registry/auth:/auth:z \
    -e "REGISTRY_AUTH=htpasswd" -e "REGISTRY_AUTH_HTPASSWD_REALM=Registry" \
    -e "REGISTRY_HTTP_SECRET=ALongRandomSecretForRegistry" \
    -e REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd -v /nfs/registry/certs:/certs:z \
    -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/domain.crt \
    -e REGISTRY_HTTP_TLS_KEY=/certs/domain.key docker.io/library/registry:2
# Trying to pull docker.io/library/registry:2...
# Getting image source signatures
# Copying blob cbdbe7a5bc2a done
# Copying blob c1cc712bcecd done
# Copying blob 47112e65547d done
# Copying blob 3db6272dcbfa done
# Copying blob 46bcb632e506 done
# Copying config 2d4f4b5309 done
# Writing manifest to image destination
# Storing signatures
# be06131e5dc4b98a1f55fdefc6afa6989cfbc8d878b6d65cf40426e96e2bede1

sudo podman start poc-registry
# poc-registry

sudo podman ps
# CONTAINER ID  IMAGE                         COMMAND               CREATED        STATUS             PORTS  NAMES
# be06131e5dc4  docker.io/library/registry:2  /etc/docker/regis...  2 minutes ago  Up 39 seconds ago         poc-registry

curl -u dummy:dummy -k \
    https://provision.$GUID.dynamic.opentlc.com:5000/v2/_catalog
# {"repositories":[]}

export IRONIC_DATA_DIR=/nfs/ocp/ironic
export IRONIC_IMAGES_DIR="${IRONIC_DATA_DIR}/html/images"
export IRONIC_IMAGE=quay.io/metal3-io/ironic:master
sudo mkdir -p $IRONIC_IMAGES_DIR
sudo chown -R "${USER}:users" "$IRONIC_DATA_DIR"
sudo find $IRONIC_DATA_DIR -type d -print0 | xargs -0 chmod 755
sudo chmod -R +r $IRONIC_DATA_DIR

sudo podman run -d --net host --privileged --name httpd --pod ironic-pod \
    -v $IRONIC_DATA_DIR:/shared --entrypoint /bin/runhttpd ${IRONIC_IMAGE}
# Trying to pull quay.io/metal3-io/ironic:master...
# Getting image source signatures
# Copying blob 3c72a8ed6814 done
# Copying blob dedbfd2c2275 done
# (...)
# Copying blob db435f5910cb done
# Copying config 3733498f02 done
# Writing manifest to image destination
# Storing signatures
# f069949f68fa147206d154417a22c20c49983f0c5b79e9c06d56750e9d3f470d

sudo podman ps
# CONTAINER ID  IMAGE                            COMMAND               CREATED         STATUS             PORTS  NAMES
# f069949f68fa  quay.io/metal3-io/ironic:master                        8 seconds ago   Up 7 seconds ago          httpd
# be06131e5dc4  docker.io/library/registry:2     /etc/docker/regis...  22 minutes ago  Up 20 minutes ago         poc-registry

curl http://provision.$GUID.dynamic.opentlc.com/images
# <!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 2.0//EN">
# <html><head>
# <title>301 Moved Permanently</title>
# </head><body>
# <h1>Moved Permanently</h1>
# <p>The document has moved <a href="http://provision.schmaustech.dynamic.opentlc.com/images/">here</a>.</p>
# </body></html>

echo -n 'dummy:dummy' | base64 -w0 && echo
# ZHVtbXk6ZHVtbXk=

cat <<EOF > ~/reg-secret.txt
"provision.$GUID.dynamic.opentlc.com:5000": {
    "email": "dummy@redhat.com",
    "auth": "$(echo -n 'dummy:dummy' | base64 -w0)"
}
EOF

export PULLSECRET=$HOME/pull-secret.json
cp $PULLSECRET $PULLSECRET.orig
cat $PULLSECRET | jq ".auths += {`cat ~/reg-secret.txt`}" > $PULLSECRET
cat $PULLSECRET | tr -d '[:space:]' > tmp-secret
mv -f tmp-secret $PULLSECRET
rm -f ~/reg-secret.txt
sed -i -e 's/^/  /' $(pwd)/domain.crt
echo "additionalTrustBundle: |" >> $HOME/scripts/install-config.yaml
cat $HOME/scripts/domain.crt >> $HOME/scripts/install-config.yaml
sed -i "s/pullSecret:.*/pullSecret: \'$(cat $PULLSECRET)\'/g" \
    $HOME/scripts/install-config.yaml

grep pullSecret install-config.yaml | sed 's/^pullSecret: //' | tr -d \' | jq .
# (...)
#     "provision.9mj2p.dynamic.opentlc.com:5000": {
#       "email": "dummy@redhat.com",
#       "auth": "ZHVtbXk6ZHVtbXk="
#     }
#   }
# }

cat install-config.yaml

export UPSTREAM_REPO="quay.io/openshift-release-dev/ocp-release:$VERSION-x86_64"
export PULLSECRET=$HOME/pull-secret.json
export LOCAL_REG="provision.$GUID.dynamic.opentlc.com:5000"
export LOCAL_REPO='ocp4/openshift4'

oc adm release mirror -a $PULLSECRET --from=$UPSTREAM_REPO \
    --to-release-image=$LOCAL_REG/$LOCAL_REPO:$VERSION --to=$LOCAL_REG/$LOCAL_REPO

INSTALL_COMMIT=$(./openshift-baremetal-install version | grep commit | cut -d' ' -f4)

IMAGE_JSON=$(curl -s \
	https://raw.githubusercontent.com/openshift/installer/${INSTALL_COMMIT}/data/data/rhcos.json)

echo $IMAGE_JSON | jq .baseURI
# "https://releases-art-rhcos.svc.ci.openshift.org/art/storage/releases/rhcos-4.5/45.82.202008010929-0/x86_64/"

echo $IMAGE_JSON | jq .images.qemu
# {
#   "path": "rhcos-45.82.202008010929-0-qemu.x86_64.qcow2.gz",
#   "sha256": "80ab9b70566c50a7e0b5e62626e5ba391a5f87ac23ea17e5d7376dcc1e2d39ce",
#   "size": 898670890,
#   "uncompressed-sha256": "c9e2698d0f3bcc48b7c66d7db901266abf27ebd7474b6719992de2d8db96995a",
#   "uncompressed-size": 2449014784
# }

echo $IMAGE_JSON | jq .images.openstack
# {
#   "path": "rhcos-45.82.202008010929-0-openstack.x86_64.qcow2.gz",
#   "sha256": "359e7c3560fdd91e64cd0d8df6a172722b10e777aef38673af6246f14838ab1a",
#   "size": 896764070,
#   "uncompressed-sha256": "036a497599863d9470d2ca558cca3c4685dac06243709afde40ad008dce5a8ac",
#   "uncompressed-size": 2400518144
# }

URL_BASE=$(echo $IMAGE_JSON | jq -r .baseURI)
QEMU_IMAGE_NAME=$(echo $IMAGE_JSON | jq -r .images.qemu.path)
QEMU_IMAGE_SHA256=$(echo $IMAGE_JSON | jq -r .images.qemu.sha256)
QEMU_IMAGE_UNCOMPRESSED_SHA256=$(echo $IMAGE_JSON | jq -r '.images.qemu."uncompressed-sha256"')
OPENSTACK_IMAGE_NAME=$(echo $IMAGE_JSON | jq -r .images.openstack.path)
OPENSTACK_IMAGE_SHA256=$(echo $IMAGE_JSON | jq -r .images.openstack.sha256)

curl -L -o ${IRONIC_DATA_DIR}/html/images/${QEMU_IMAGE_NAME} \
	${URL_BASE}/${QEMU_IMAGE_NAME}

curl -L -o ${IRONIC_DATA_DIR}/html/images/${OPENSTACK_IMAGE_NAME} \
	${URL_BASE}/${OPENSTACK_IMAGE_NAME}

echo "$QEMU_IMAGE_SHA256 ${IRONIC_DATA_DIR}/html/images/${QEMU_IMAGE_NAME}" \
	| sha256sum -c
# /nfs/ocp/ironic/html/images/rhcos-45.82.202008010929-0-qemu.x86_64.qcow2.gz: OK

echo "$OPENSTACK_IMAGE_SHA256 ${IRONIC_DATA_DIR}/html/images/${OPENSTACK_IMAGE_NAME}" \
	| sha256sum -c
# /nfs/ocp/ironic/html/images/rhcos-45.82.202008010929-0-openstack.x86_64.qcow2.gz: OK    

grep http://10.20.0.2 install-config.yaml
    # bootstrapOSImage: http://10.20.0.2/images/RHCOS_QEMU_IMAGE
    # clusterOSImage: http://10.20.0.2/images/RHCOS_OPENSTACK_IMAGE

RHCOS_QEMU_IMAGE=${QEMU_IMAGE_NAME}?sha256=${QEMU_IMAGE_UNCOMPRESSED_SHA256}

RHCOS_OPENSTACK_IMAGE=${OPENSTACK_IMAGE_NAME}?sha256=${OPENSTACK_IMAGE_SHA256}

sed -i "s/RHCOS_QEMU_IMAGE/$RHCOS_QEMU_IMAGE/g" \
	$HOME/scripts/install-config.yaml

sed -i "s/RHCOS_OPENSTACK_IMAGE/$RHCOS_OPENSTACK_IMAGE/g" \
	$HOME/scripts/install-config.yaml

grep http://10.20.0.2 install-config.yaml
    # bootstrapOSImage: http://10.20.0.2/images/rhcos-45.82.202008010929-0-qemu.x86_64.qcow2.gz?sha256=c9e2698d0f3bcc48b7c66d7db901266abf27ebd7474b6719992de2d8db96995a
    # clusterOSImage: http://10.20.0.2/images/rhcos-45.82.202008010929-0-openstack.x86_64.qcow2.gz?sha256=359e7c3560fdd91e64cd0d8df6a172722b10e777aef38673af6246f14838ab1a

curl -o /dev/null http://10.20.0.2/images/${RHCOS_QEMU_IMAGE}
curl -o /dev/null http://10.20.0.2/images/${RHCOS_OPENSTACK_IMAGE}

cat install-config.yaml

for i in 0 1 2 3 4 5
 do
 /usr/bin/ipmitool -I lanplus -H10.20.0.3 -p620$i -Uadmin -Predhat chassis power off
 done
# Chassis Power Control: Down/Off
# Chassis Power Control: Down/Off
# Chassis Power Control: Down/Off
# Chassis Power Control: Down/Off
# Chassis Power Control: Down/Off
# Chassis Power Control: Down/Off

mkdir $HOME/scripts/ocp
cp $HOME/scripts/install-config.yaml $HOME/scripts/ocp
$HOME/scripts/openshift-baremetal-install --dir=ocp --log-level debug create manifests

ls -l $HOME/scripts/ocp/manifests/

$HOME/scripts/openshift-baremetal-install --dir=ocp --log-level debug create cluster

oc --kubeconfig $HOME/scripts/ocp/auth/kubeconfig get nodes

export KUBECONFIG=$HOME/scripts/ocp/auth/kubeconfig

oc get nodes
oc get clusteroperators

oc patch configs.imageregistry.operator.openshift.io cluster --type merge \
	--patch '{"spec":{"storage":{"emptyDir":{}}}}'

oc patch configs.imageregistry.operator.openshift.io cluster --type merge \
	--patch '{"spec":{"managementState":"Managed"}}'

oc get pod -n openshift-image-registry


oc get pods -n openshift-machine-api
POD_NAME=$(oc get pods -n openshift-machine-api -o json | jq -r  .items[] | select( .metadata.name | test("metal3.")) | .metadata.name)
echo $POD_NAME

oc describe pod $POD_NAME -n openshift-machine-api

oc get baremetalhosts -n openshift-machine-api

export OS_TOKEN=fake-token
export OS_URL=http://172.22.0.3:6385
openstack baremetal node list

oc get baremetalhosts -n openshift-machine-api \
	-o=custom-columns=NAME:.metadata.name,CONSUMER:.spec.consumerRef.name

oc get machine/$GUID-master-0 -n openshift-machine-api -o yaml

grep -A2 compute ~/scripts/install-config.yaml
# compute:
# - name: worker
#   replicas: 2

IPMI_PORT=$(for PORT in 6200 6201 6202 6203 6204 6205; do
	grep -q $PORT ~/scripts/install-config.yaml|| echo $PORT
done)

echo $IPMI_PORT
# 6203

cat << EOF > ~/bmh.yaml
---
apiVersion: v1
kind: Secret
metadata:
  name: worker-2-bmc-secret
type: Opaque
data:
  username: YWRtaW4=
  password: cmVkaGF0
---
apiVersion: metal3.io/v1alpha1
kind: BareMetalHost
metadata:
  name: worker-2
spec:
  online: true
  bootMACAddress: de:ad:be:ef:00:52
  hardwareProfile: openstack
  bmc:
    address: ipmi://10.20.0.3:${IPMI_PORT}
    credentialsName: worker-2-bmc-secret
EOF

oc create -f ~/bmh.yaml -n openshift-machine-api

oc get baremetalhosts -n openshift-machine-api

export OS_URL=http://172.22.0.3:6385; export OS_TOKEN=fake-token
openstack baremetal node list

watch -n10 oc get baremetalhosts -n openshift-machine-api

oc get baremetalhosts/worker-2 -n openshift-machine-api

oc -n openshift-machine-api get machineset

oc -n openshift-machine-api scale machineset $GUID-worker-0 --replicas=3

oc get baremetalhosts -n openshift-machine-api

openstack baremetal node list

watch -n10 "openstack baremetal node list && echo \
	&& oc get baremetalhosts -n openshift-machine-api && echo \
	&& oc get nodes"

oc get nodes

cat ~/scripts/10_volume-attach.sh

unset OS_URL OS_TOKEN
~/scripts/10_volume-attach.sh
# (no output)
echo $?
# 0

oc debug node/worker-0.$GUID.dynamic.opentlc.com
chroot /host
lsblk
exit

oc label nodes worker-0.$GUID.dynamic.opentlc.com cluster.ocs.openshift.io/openshift-storage=''
node/worker-0 labeled

oc label nodes worker-1.$GUID.dynamic.opentlc.com cluster.ocs.openshift.io/openshift-storage=''
node/worker-1 labeled

oc label nodes worker-2.$GUID.dynamic.opentlc.com cluster.ocs.openshift.io/openshift-storage=''
node/worker-2 labeled

oc get nodes -l cluster.ocs.openshift.io/openshift-storage=

oc get pods -n local-storage

cat << EOF > ~/local-storage.yaml
apiVersion: local.storage.openshift.io/v1
kind: LocalVolume
metadata:
  name: local-block
  namespace: local-storage
spec:
  nodeSelector:
    nodeSelectorTerms:
    - matchExpressions:
        - key: cluster.ocs.openshift.io/openshift-storage
          operator: In
          values:
          - ""
  storageClassDevices:
    - storageClassName: localblock
      volumeMode: Block
      devicePaths:
        - /dev/sdb
EOF

oc get nodes -l cluster.ocs.openshift.io/openshift-storage

oc create -f ~/local-storage.yaml

oc -n local-storage get pods

oc get pv

oc get sc

oc get pods -n openshift-storage

oc get storageclass

oc patch OCSInitialization ocsinit -n openshift-storage \
    --type json --patch '[{ "op": "replace", "path": "/spec/enableCephTools", "value": true }]'

oc get pods -n openshift-storage | grep rook-ceph-tools

oc exec -it rook-ceph-tools-7fcff79f44-g9r6t -n openshift-storage bash
ceph -s
exit

oc get pods -n openshift-cnv

oc get csv -n openshift-cnv

oc get nns -A

oc get nns/worker-2.$GUID.dynamic.opentlc.com -o yaml

cat << EOF | oc apply -f -
apiVersion: nmstate.io/v1alpha1
kind: NodeNetworkConfigurationPolicy
metadata:
  name: worker-brext-ens3
spec:
  nodeSelector:
    node-role.kubernetes.io/worker: ""
  desiredState:
    interfaces:
      - name: brext
        description: brext with ens3
        type: linux-bridge
        state: up
        ipv4:
          enabled: true
          dhcp: true
        bridge:
          options:
            stp:
              enabled: false
          port:
            - name: ens3
EOF

oc get nnce
# NAME                                                   STATUS
# master-0.hhnfk.dynamic.opentlc.com.worker-brext-ens3   NodeSelectorNotMatching
# master-1.hhnfk.dynamic.opentlc.com.worker-brext-ens3   NodeSelectorNotMatching
# master-2.hhnfk.dynamic.opentlc.com.worker-brext-ens3   NodeSelectorNotMatching
# worker-0.hhnfk.dynamic.opentlc.com.worker-brext-ens3   ConfigurationProgressing
# worker-1.hhnfk.dynamic.opentlc.com.worker-brext-ens3   ConfigurationProgressing
# worker-2.hhnfk.dynamic.opentlc.com.worker-brext-ens3   ConfigurationProgressing

oc debug node/worker-0.$GUID.dynamic.opentlc.com
# chroot /host
# ip a show brext
# exit

oc project default
cat << EOF | oc apply -f -
apiVersion: "k8s.cni.cncf.io/v1"
kind: NetworkAttachmentDefinition
metadata:
  name: brext
  annotations:
    k8s.v1.cni.cncf.io/resourceName: bridge.network.kubevirt.io/brext
spec:
  config: '{
    "cniVersion": "0.3.1",
    "name": "brext",
    "plugins": [
      {
        "type": "cnv-bridge",
        "bridge": "brext"
      },
      {
        "type": "tuning"
      }
    ]
  }'
EOF

oc project default
oc new-app nodeshift/centos7-s2i-nodejs:12.x~https://github.com/vrutkovs/DuckHunt-JS
oc logs duckhunt-js-1-build -f

oc get pods
oc expose svc/duckhunt-js
oc get route duckhunt-js

cat << EOF > ~/virtualmachine-fedora.yaml
apiVersion: kubevirt.io/v1alpha3
kind: VirtualMachine
metadata:
  annotations:
    kubevirt.io/latest-observed-api-version: v1alpha3
    kubevirt.io/storage-observed-api-version: v1alpha3
    name.os.template.kubevirt.io/silverblue32: Fedora 31 or higher
  name: fedora
  namespace: default
  labels:
    app: fedora
    flavor.template.kubevirt.io/medium: 'true'
    os.template.kubevirt.io/silverblue32: 'true'
    vm.kubevirt.io/template: fedora-desktop-medium-v0.11.3
    vm.kubevirt.io/template.namespace: openshift
    vm.kubevirt.io/template.revision: '1'
    vm.kubevirt.io/template.version: v0.11.3
    workload.template.kubevirt.io/desktop: 'true'
spec:
  dataVolumeTemplates:
    - apiVersion: cdi.kubevirt.io/v1alpha1
      kind: DataVolume
      metadata:
        creationTimestamp: null
        name: fedora-rootdisk
      spec:
        pvc:
          accessModes:
            - ReadWriteMany
          resources:
            requests:
              storage: 10Gi
          storageClassName: ocs-storagecluster-ceph-rbd
          volumeMode: Block
        source:
          http:
            url: >-
              https://download.fedoraproject.org/pub/fedora/linux/releases/32/Cloud/x86_64/images/Fedora-Cloud-Base-32-1.6.x86_64.raw.xz
  template:
    metadata:
      creationTimestamp: null
      labels:
        flavor.template.kubevirt.io/medium: 'true'
        kubevirt.io/domain: fedora
        kubevirt.io/size: medium
        os.template.kubevirt.io/silverblue32: 'true'
        vm.kubevirt.io/name: fedora
        workload.template.kubevirt.io/desktop: 'true'
    spec:
      domain:
        cpu:
          cores: 1
          sockets: 1
          threads: 1
        devices:
          autoattachPodInterface: false
          disks:
            - bootOrder: 1
              disk:
                bus: virtio
              name: rootdisk
            - disk:
                bus: virtio
              name: cloudinitdisk
          inputs:
            - bus: virtio
              name: tablet
              type: tablet
          interfaces:
            - bridge: {}
              model: virtio
              name: nic-0
          networkInterfaceMultiqueue: true
          rng: {}
        machine:
          type: pc-q35-rhel8.2.0
        resources:
          requests:
            memory: 4Gi
      evictionStrategy: LiveMigrate
      hostname: fedora32
      networks:
        - multus:
            networkName: brext
          name: nic-0
      terminationGracePeriodSeconds: 180
      volumes:
        - dataVolume:
            name: fedora-rootdisk
          name: rootdisk
        - cloudInitNoCloud:
            userData: |-
              #cloud-config
              name: default
              hostname: fedora32
              password: redhat
              chpasswd: {expire: False}
          name: cloudinitdisk
EOF

oc create -f ~/virtualmachine-fedora.yaml 

oc logs importer-fedora-rootdisk -f

sudo dnf -y install kubevirt-virtctl

virtctl console fedora

``` 